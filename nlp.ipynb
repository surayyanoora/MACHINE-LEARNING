{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9R7RreF68qdiDNAaaaWkZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"307FDfPpUyeb"},"outputs":[],"source":["import nltk"]},{"cell_type":"code","source":["help(nltk)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRu5myugVERb","executionInfo":{"status":"ok","timestamp":1717052979481,"user_tz":-330,"elapsed":473,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"9ee1f755-b81c-485f-d3e0-86f98925cdbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on package nltk:\n","\n","NAME\n","    nltk\n","\n","DESCRIPTION\n","    The Natural Language Toolkit (NLTK) is an open source Python library\n","    for Natural Language Processing.  A free online book is available.\n","    (If you use the library for academic research, please cite the book.)\n","    \n","    Steven Bird, Ewan Klein, and Edward Loper (2009).\n","    Natural Language Processing with Python.  O'Reilly Media Inc.\n","    https://www.nltk.org/book/\n","    \n","    isort:skip_file\n","    \n","    @version: 3.8.1\n","\n","PACKAGE CONTENTS\n","    app (package)\n","    book\n","    ccg (package)\n","    chat (package)\n","    chunk (package)\n","    classify (package)\n","    cli\n","    cluster (package)\n","    collections\n","    collocations\n","    compat\n","    corpus (package)\n","    data\n","    decorators\n","    downloader\n","    draw (package)\n","    featstruct\n","    grammar\n","    help\n","    inference (package)\n","    internals\n","    jsontags\n","    langnames\n","    lazyimport\n","    lm (package)\n","    metrics (package)\n","    misc (package)\n","    parse (package)\n","    probability\n","    sem (package)\n","    sentiment (package)\n","    stem (package)\n","    tag (package)\n","    tbl (package)\n","    test (package)\n","    text\n","    tgrep\n","    tokenize (package)\n","    toolbox\n","    translate (package)\n","    tree (package)\n","    treeprettyprinter\n","    treetransforms\n","    twitter (package)\n","    util\n","    wsd\n","\n","SUBMODULES\n","    agreement\n","    aline\n","    api\n","    arlstem\n","    arlstem2\n","    association\n","    bleu_score\n","    bllip\n","    boxer\n","    brill\n","    brill_trainer\n","    casual\n","    chart\n","    chrf_score\n","    cistem\n","    confusionmatrix\n","    corenlp\n","    crf\n","    decisiontree\n","    dependencygraph\n","    destructive\n","    discourse\n","    distance\n","    drt\n","    earleychart\n","    evaluate\n","    featurechart\n","    gale_church\n","    gdfa\n","    gleu_score\n","    glue\n","    hmm\n","    hunpos\n","    ibm1\n","    ibm2\n","    ibm3\n","    ibm4\n","    ibm5\n","    ibm_model\n","    isri\n","    lancaster\n","    legality_principle\n","    lfg\n","    linearlogic\n","    logic\n","    mace\n","    malt\n","    mapping\n","    maxent\n","    megam\n","    meteor_score\n","    mwe\n","    naivebayes\n","    nist_score\n","    nonprojectivedependencyparser\n","    paice\n","    pchart\n","    perceptron\n","    phrase_based\n","    porter\n","    positivenaivebayes\n","    projectivedependencyparser\n","    prover9\n","    punkt\n","    recursivedescent\n","    regexp\n","    relextract\n","    repp\n","    resolution\n","    ribes_score\n","    rslp\n","    rte_classify\n","    scikitlearn\n","    scores\n","    segmentation\n","    senna\n","    sequential\n","    sexpr\n","    shiftreduce\n","    simple\n","    snowball\n","    sonority_sequencing\n","    spearman\n","    stack_decoder\n","    stanford\n","    stanford_segmenter\n","    tableau\n","    tadm\n","    textcat\n","    texttiling\n","    tnt\n","    toktok\n","    transitionparser\n","    treebank\n","    viterbi\n","    weka\n","    wordnet\n","\n","FUNCTIONS\n","    demo()\n","        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n","    \n","    tee(iterable, n=2, /)\n","        Returns a tuple of n independent iterators.\n","\n","DATA\n","    RUS_PICKLE = 'taggers/averaged_perceptron_tagger_ru/averaged_perceptro...\n","    SLASH = *slash*\n","    TYPE = *type*\n","    __author_email__ = 'nltk.team@gmail.com'\n","    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n","    __copyright__ = 'Copyright (C) 2001-2023 NLTK Project.\\n\\nDistribut......\n","    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n","    __license__ = 'Apache License, Version 2.0'\n","    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ...NL...\n","    __maintainer__ = 'NLTK Team'\n","    __maintainer_email__ = 'nltk.team@gmail.com'\n","    __url__ = 'https://www.nltk.org/'\n","    app = <LazyModule 'nltk.app'>\n","    chat = <LazyModule 'nltk.chat'>\n","    corpus = <LazyModule 'nltk.corpus'>\n","    infile = <_io.TextIOWrapper name='/usr/local/lib/python3....packages/n...\n","    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n","    toolbox = <LazyModule 'nltk.toolbox'>\n","    version_file = '/usr/local/lib/python3.10/dist-packages/nltk/VERSION'\n","\n","VERSION\n","    3.8.1\n","\n","AUTHOR\n","    NLTK Team\n","\n","FILE\n","    /usr/local/lib/python3.10/dist-packages/nltk/__init__.py\n","\n","\n"]}]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jl4cenZSWHX2","executionInfo":{"status":"ok","timestamp":1717053206252,"user_tz":-330,"elapsed":433,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"add0505a-dd71-475b-e38a-761ae6a43556"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","stopwordss=stopwords.words('english')"],"metadata":{"id":"PBGebBA_VTG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stopwordss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwhfwxN8WR5F","executionInfo":{"status":"ok","timestamp":1717053266964,"user_tz":-330,"elapsed":387,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"2016773c-ca6d-4122-d0e7-aab8b137350c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be',\n"," 'been',\n"," 'being',\n"," 'have',\n"," 'has',\n"," 'had',\n"," 'having',\n"," 'do',\n"," 'does',\n"," 'did',\n"," 'doing',\n"," 'a',\n"," 'an',\n"," 'the',\n"," 'and',\n"," 'but',\n"," 'if',\n"," 'or',\n"," 'because',\n"," 'as',\n"," 'until',\n"," 'while',\n"," 'of',\n"," 'at',\n"," 'by',\n"," 'for',\n"," 'with',\n"," 'about',\n"," 'against',\n"," 'between',\n"," 'into',\n"," 'through',\n"," 'during',\n"," 'before',\n"," 'after',\n"," 'above',\n"," 'below',\n"," 'to',\n"," 'from',\n"," 'up',\n"," 'down',\n"," 'in',\n"," 'out',\n"," 'on',\n"," 'off',\n"," 'over',\n"," 'under',\n"," 'again',\n"," 'further',\n"," 'then',\n"," 'once',\n"," 'here',\n"," 'there',\n"," 'when',\n"," 'where',\n"," 'why',\n"," 'how',\n"," 'all',\n"," 'any',\n"," 'both',\n"," 'each',\n"," 'few',\n"," 'more',\n"," 'most',\n"," 'other',\n"," 'some',\n"," 'such',\n"," 'no',\n"," 'nor',\n"," 'not',\n"," 'only',\n"," 'own',\n"," 'same',\n"," 'so',\n"," 'than',\n"," 'too',\n"," 'very',\n"," 's',\n"," 't',\n"," 'can',\n"," 'will',\n"," 'just',\n"," 'don',\n"," \"don't\",\n"," 'should',\n"," \"should've\",\n"," 'now',\n"," 'd',\n"," 'll',\n"," 'm',\n"," 'o',\n"," 're',\n"," 've',\n"," 'y',\n"," 'ain',\n"," 'aren',\n"," \"aren't\",\n"," 'couldn',\n"," \"couldn't\",\n"," 'didn',\n"," \"didn't\",\n"," 'doesn',\n"," \"doesn't\",\n"," 'hadn',\n"," \"hadn't\",\n"," 'hasn',\n"," \"hasn't\",\n"," 'haven',\n"," \"haven't\",\n"," 'isn',\n"," \"isn't\",\n"," 'ma',\n"," 'mightn',\n"," \"mightn't\",\n"," 'mustn',\n"," \"mustn't\",\n"," 'needn',\n"," \"needn't\",\n"," 'shan',\n"," \"shan't\",\n"," 'shouldn',\n"," \"shouldn't\",\n"," 'wasn',\n"," \"wasn't\",\n"," 'weren',\n"," \"weren't\",\n"," 'won',\n"," \"won't\",\n"," 'wouldn',\n"," \"wouldn't\"]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGfqqpcSXNGn","executionInfo":{"status":"ok","timestamp":1717053483279,"user_tz":-330,"elapsed":871,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"a6a8e62b-4892-4e1f-fcf5-85fcac4fb34a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["sentence=\"at eight o clock on thursday morning,hello how are you\"\n","\n","tokens = nltk.word_tokenize(sentence)\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5NkR6HMAWXnP","executionInfo":{"status":"ok","timestamp":1717053994399,"user_tz":-330,"elapsed":6,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"8e0be66b-0472-429f-fc81-a970772d36bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['at',\n"," 'eight',\n"," 'o',\n"," 'clock',\n"," 'on',\n"," 'thursday',\n"," 'morning',\n"," ',',\n"," 'hello',\n"," 'how',\n"," 'are',\n"," 'you']"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","sentence=\"at eight o clock on thursday morning,hello how are you\"\n","stopwordss=set(stopwords.words('english'))\n","tokens=word_tokenize(sentence)\n","tokens\n","words=[w for w in tokens if not w in stopwordss]\n","words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtsEbdLWXAFx","executionInfo":{"status":"ok","timestamp":1717054001676,"user_tz":-330,"elapsed":1548,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"f0b75f25-b78e-481f-8fc7-60db67a3960a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['eight', 'clock', 'thursday', 'morning', ',', 'hello']"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":[],"metadata":{"id":"dWkKWu0O1JM8"}},{"cell_type":"code","source":["words=[w.lower() for w in tokens if not w in stopwordss]\n","words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYHSCnJ3Ynk5","executionInfo":{"status":"ok","timestamp":1717054095061,"user_tz":-330,"elapsed":1571,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"9b7acb58-d0b2-411d-8a4a-90ebb8453c3a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['eight', 'clock', 'thursday', 'morning', ',', 'hello']"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["#this is not good\n","#this, is , not,good\n","\n","ngrams\n","ngram1=1    ngram=2           ngram3=3\n","this        this is            this is not\n","is          is not             is not good\n","not"],"metadata":{"id":"NAhL75oxZ_QX"}},{"cell_type":"code","source":["from nltk.util import ngrams\n","\n","Ngrams=ngrams(sequence=nltk.word_tokenize(sentence),n=1)\n","for grms in Ngrams:\n","  print(grms)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cqKlYw2KayRG","executionInfo":{"status":"ok","timestamp":1717055134258,"user_tz":-330,"elapsed":423,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"c5887caf-c05a-42e4-eda5-c816fc4e34f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('at',)\n","('eight',)\n","('o',)\n","('clock',)\n","('on',)\n","('thursday',)\n","('morning',)\n","(',',)\n","('hello',)\n","('how',)\n","('are',)\n","('you',)\n"]}]},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","sb = SnowballStemmer('english')\n","words = [\"eight\",\"english\",\"paragraphs\",\"studying\",\"learning\",\"studied\"]\n","for w in words:\n","   print(w,\"+\",sb.stem(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8STCL4NcBd0","executionInfo":{"status":"ok","timestamp":1717055239429,"user_tz":-330,"elapsed":422,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"da502d6d-c643-4dc6-9dc3-cbebfa66f4ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["eight + eight\n","english + english\n","paragraphs + paragraph\n","studying + studi\n","learning + learn\n","studied + studi\n"]}]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","porter = PorterStemmer()\n","words = [\"eight\",\"english\",\"paragraphs\",\"studying\",\"learning\",\"studied\"]\n","print(\"words,porter stem\")\n","for w in words:\n","   print(w,\"+\",porter.stem(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjLV5fb9d7Dn","executionInfo":{"status":"ok","timestamp":1717055449786,"user_tz":-330,"elapsed":409,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"6493d579-5a02-4b24-d2ab-41415cd869a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["words,porter stem\n","eight + eight\n","english + english\n","paragraphs + paragraph\n","studying + studi\n","learning + learn\n","studied + studi\n"]}]},{"cell_type":"code","source":["nltk.download(\"wordnet\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nn7_NiR5fFnG","executionInfo":{"status":"ok","timestamp":1717055622154,"user_tz":-330,"elapsed":429,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"ffc4b972-9eff-4029-efe8-29e7a8fef1e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","lem = WordNetLemmatizer()\n","print(\"paragraphs\",lem.lemmatize(\"paragraphs\"))\n","\n","print(\"swimming\",lem.lemmatize(\"swimming\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7E4e8WyepoO","executionInfo":{"status":"ok","timestamp":1717055977983,"user_tz":-330,"elapsed":882,"user":{"displayName":"Noora m","userId":"10494114322383028308"}},"outputId":"c2e490ee-756f-42fd-bf5b-5e0bceb05520"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["paragraphs paragraph\n","swimming swimming\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NltRH4cEfpUk"},"execution_count":null,"outputs":[]}]}